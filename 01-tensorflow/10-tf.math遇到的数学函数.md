# tf.math遇到的数学函数

## 1. tf.exp

```py
tf.math.exp(
    x,
    name=None
)
```

计算

```math
e^x
```

返回的也是一个Tensor

## 2. tf.reduce_sum

降维求和

```py
tf.math.reduce_sum(
    input_tensor,
    axis=None,
    keepdims=None,
    name=None,
    reduction_indices=None,
    keep_dims=None
)

import tensorflow as tf

x = tf.constant([[1, 1, 1], [1, 1, 1]])
tf.reduce_sum(x, 0)  
# [2, 2, 2]
tf.reduce_sum(x, 1)  
# [3, 3]
tf.reduce_sum(x, [0, 1])  
# 6
```

## 4. tf.nn.softmax

计算softmax激活,计算每一项的概率(全部转换为0-1之间的值)，Softmax简单的说就是把一个N*1的向量归一化为（0，1）之间的值，由于其中采用指数运算，使得向量中数值较大的量特征更加明显。
计算指定维度上面的各项概率。

```py
tf.nn.softmax(
    logits,
    axis=None,
    name=None,
    dim=None
)
```

```py
    softmax = tf.exp(logits) / tf.reduce_sum(tf.exp(logits), axis)
```

```py
import tensorflow as tf
input = tf.constant(5, dtype=tf.float32, shape=[8,5])
op = tf.nn.softmax(input) #默认dim为1，在最后一个维度上进行softmax
with tf.Session() as sess:
    print(sess.run(op))
    op = tf.nn.softmax(input, dim=0)
    print(sess.run(op))
>>> [[ 0.2  0.2  0.2  0.2  0.2]
 [ 0.2  0.2  0.2  0.2  0.2]
 [ 0.2  0.2  0.2  0.2  0.2]
 [ 0.2  0.2  0.2  0.2  0.2]
 [ 0.2  0.2  0.2  0.2  0.2]
 [ 0.2  0.2  0.2  0.2  0.2]
 [ 0.2  0.2  0.2  0.2  0.2]
 [ 0.2  0.2  0.2  0.2  0.2]]
>>>[[ 0.125  0.125  0.125  0.125  0.125]
 [ 0.125  0.125  0.125  0.125  0.125]
 [ 0.125  0.125  0.125  0.125  0.125]
 [ 0.125  0.125  0.125  0.125  0.125]
 [ 0.125  0.125  0.125  0.125  0.125]
 [ 0.125  0.125  0.125  0.125  0.125]
 [ 0.125  0.125  0.125  0.125  0.125]
 [ 0.125  0.125  0.125  0.125  0.125]]
```

## 5. tf.reduce_mean

```py
tf.math.reduce_mean(
    input_tensor,
    axis=None,
    keepdims=None,
    name=None,
    reduction_indices=None,
    keep_dims=None
)
```

计算在axis维上的平均值，输出维度会减少1，如果axis为None，只输出一个值。  
如果keepdims为True，保持维度，长度为1.

```py
x = tf.constant([[1., 1.], [2., 2.]])
tf.reduce_mean(x)  # 1.5
tf.reduce_mean(x, 0)  # [1.5, 1.5]
tf.reduce_mean(x, 1)  # [1.,  2.]
```

## 6. tf.clip_by_value

```py
tf.clip_by_value(
    t,
    clip_value_min,
    clip_value_max,
    name=None
)
```

将t的值修改在min到max之间，如果小于min改为min，大于max改为max，在这之间则不修改

## 7. tf.squared_difference

返回差的平方

```py
tf.math.squared_difference(
    x,
    y,
    name=None
)
```

返回`(x-y)(x-y)`

## 8. tf.argmax

```py
tf.math.argmax(
    input,
    axis=None,
    name=None,
    dimension=None,
    output_type=tf.dtypes.int64
)
```

返回指定维度最大值的下标，注意axis为0代表0维被删除。

```py
a = tf.Variable([[0, 2, 1], [3, 2, 3]]
tf.argmax(a, 0)
> [1, 0, 1]

tf.argmax(a, 1)
> [1, 0]
```

## 9. tf.equal

```py
tf.math.equal(
    x,
    y,
    name=None
)
```

返回(x == y)，注意这可以是一个矩阵

```py
a = tf.Variable([[1, 2, 3], [3, 2, 1]], dtype=tf.int32)
b = tf.Variable([[0, 2, 1], [3, 2, 3]], dtype=tf.int32)
c = tf.argmax(a, 1)
d = tf.argmax(b, 1)
e = tf.equal(c, d)
>>> [False,  True]
```

## 10. tf.cast

```py
tf.dtypes.cast(
    x,
    dtype,
    name=None
)
```

类型转换，转换为指定类型

```py
x = tf.constant([1.8, 2.2], dtype=tf.float32)
tf.cast(x, tf.int32)  # [1, 2], dtype=tf.int32
```

## 11. tf.reshape()

```py
tf.reshape(
    tensor,
    shape,
    name=None
)
```

将输入的tensor转换成shape为输入shape的tensor输出。-1做推断。

```py
# tensor 't' is [1, 2, 3, 4, 5, 6, 7, 8, 9]
# tensor 't' has shape [9]
reshape(t, [3, 3]) ==> [[1, 2, 3],
                        [4, 5, 6],
                        [7, 8, 9]]

# tensor 't' is [[[1, 1], [2, 2]],
#                [[3, 3], [4, 4]]]
# tensor 't' has shape [2, 2, 2]
reshape(t, [2, 4]) ==> [[1, 1, 2, 2],
                        [3, 3, 4, 4]]

# tensor 't' is [[[1, 1, 1],
#                 [2, 2, 2]],
#                [[3, 3, 3],
#                 [4, 4, 4]],
#                [[5, 5, 5],
#                 [6, 6, 6]]]
# tensor 't' has shape [3, 2, 3]
# pass '[-1]' to flatten 't'
reshape(t, [-1]) ==> [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6]

# -1 can also be used to infer the shape

# -1 is inferred to be 9:
reshape(t, [2, -1]) ==> [[1, 1, 1, 2, 2, 2, 3, 3, 3],
                         [4, 4, 4, 5, 5, 5, 6, 6, 6]]
# -1 is inferred to be 2:
reshape(t, [-1, 9]) ==> [[1, 1, 1, 2, 2, 2, 3, 3, 3],
                         [4, 4, 4, 5, 5, 5, 6, 6, 6]]
# -1 is inferred to be 3:
reshape(t, [ 2, -1, 3]) ==> [[[1, 1, 1],
                              [2, 2, 2],
                              [3, 3, 3]],
                             [[4, 4, 4],
                              [5, 5, 5],
                              [6, 6, 6]]]

# tensor 't' is [7]
# shape `[]` reshapes to a scalar,变成一个数
reshape(t, []) ==> 7
```

## 12. tf.square()

```py
tf.math.square(
    x,
    name=None
)
return x*x
```

## 13. tf.one_hot()

```py
tf.one_hot(
    indices,
    depth,
    on_value=None,
    off_value=None,
    axis=None,
    dtype=None,
    name=None
)
```

升维操作，将n维变量升为n+1维。

```py
`indice`的大小为a1 * a2 * a3 * ...

+ axis=-1 输出为a1 * a2 * a3 * .. * depth
+ axis=0 输出为depth * a1 * a2 * a3 * ..
+ axis=1 输出为a1 * a2 * a3 * depth * ..
+ ..  
```

on_value默认为1
off_value默认为0

输出的第depth维第indice位(indice < depth && indice > 0, 否则全部输出off_value)值为on_value，其余位置为off_value。

```py
indices = [0, 1, 2]
depth = 3
tf.one_hot(indices, depth)  # output: [3 x 3]
# [[1., 0., 0.],
#  [0., 1., 0.],
#  [0., 0., 1.]]

indices = [0, 2, -1, 1]
depth = 3
tf.one_hot(indices, depth,
           on_value=5.0, off_value=0.0,
           axis=-1)  # output: [4 x 3]
# [[5.0, 0.0, 0.0],  # one_hot(0)
#  [0.0, 0.0, 5.0],  # one_hot(2)
#  [0.0, 0.0, 0.0],  # one_hot(-1)
#  [0.0, 5.0, 0.0]]  # one_hot(1)

indices = [[0, 2], [1, -1]]
depth = 3
tf.one_hot(indices, depth,
           on_value=1.0, off_value=0.0,
           axis=-1)  # output: [2 x 2 x 3]
# [[[1.0, 0.0, 0.0],   # one_hot(0)
#   [0.0, 0.0, 1.0]],  # one_hot(2)
#  [[0.0, 1.0, 0.0],   # one_hot(1)
#   [0.0, 0.0, 0.0]]]  # one_hot(-1)
```

## 14. tf.random.normal

```py
tf.random.normal(
    shape,
    mean=0.0,
    stddev=1.0,
    dtype=tf.dtypes.float32,
    seed=None,
    name=None
)
```

返回一个随机正态分布

## 15. tf.squeeze && tf.expand_dim

```py
降维函数
tf.squeeze(
    input,
    axis=None,
    name=None,
    squeeze_dims=None
)
升维函数
tf.expand_dims(
    input,
    axis=None,
    name=None,
    dim=None
)
```

### tf.squeeze

去除所有值为1的维度，或者指定值为1的维度。注意能去除的维度里面的参数值必须为1.

```py
# 't' is a tensor of shape [1, 2, 1, 3, 1, 1]
tf.shape(tf.squeeze(t))  # [2, 3]

# 't' is a tensor of shape [1, 2, 1, 3, 1, 1]
tf.shape(tf.squeeze(t, [2, 4]))  # [1, 2, 3, 1]
```

### tf.expand_dim

指定位置进行维度拓展

```py
# 't' is a tensor of shape [2]
tf.shape(tf.expand_dims(t, 0))  # [1, 2]
tf.shape(tf.expand_dims(t, 1))  # [2, 1]
tf.shape(tf.expand_dims(t, -1))  # [2, 1]

# 't2' is a tensor of shape [2, 3, 5]
tf.shape(tf.expand_dims(t2, 0))  # [1, 2, 3, 5]
tf.shape(tf.expand_dims(t2, 2))  # [2, 3, 1, 5]
tf.shape(tf.expand_dims(t2, 3))  # [2, 3, 5, 1]
```
